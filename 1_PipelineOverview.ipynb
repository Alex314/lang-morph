{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd5b8f4-e4d9-4fd6-b723-6b2dc7fcb56b",
   "metadata": {},
   "source": [
    "This notebook demonstrates the abilities of the solution and describes decisions taken during development of that project.\n",
    "\n",
    "First of all, project was implemented with aim to to cover a lot of possible general applications, rather then efficiently solve some particular problems. That is, solution is slow and memory-ineffitient.\n",
    "\n",
    "The idea is to parse input text into the [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph) starting from the chain of tokens as they go in the text and adding vertices and edges by different analysers to perform named entity recognition tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9caadf7b-2f1e-48af-a3d6-5197899465ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization import text_to_tokens\n",
    "from dag import EntitiesDAG\n",
    "from analyser import (punctuation_analyser,\n",
    "                      spacing_analyser,\n",
    "                      integer_analyser,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af54ee07-9ff3-4c08-abcd-0e8e800a1de1",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Tokenization implemented as simple as possible: it keeps every consequent letters (EN, UA, RU alphabets) or consequent digits together within same token and breaks everything else into separate tokens.<br>\n",
    "The idea is to unite multiple tokens into more meaningfull entities during later analysis, while reducing possible need to further split tokens for the sake of analysis.\n",
    "\n",
    "No characters ommited during tokenization, spaces are valid tokens as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ed14c1-f5fc-4858-8294-e5c0282f7157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UINT64_C(0x123) expands to a literal\n"
     ]
    }
   ],
   "source": [
    "input_text = 'UINT64_C(0x123) expands to a literal'\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1e6736-1740-42af-aedf-e52a93d7833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UINT', '64', '_', 'C', '(', '0', 'x', '123', ')', ' ', 'expands', ' ', 'to', ' ', 'a', ' ', 'literal']\n"
     ]
    }
   ],
   "source": [
    "tokens = text_to_tokens(input_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f47d7e-643c-45bf-b363-bfe927b71a64",
   "metadata": {},
   "source": [
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8144fd2-d32c-47b3-84c4-b0ffce330876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–£–∫—Ä–∞—ó–Ω—Å—å–∫—ñ', ' ', '–Ω–∞—Ä–æ–¥', '-', '\\n', '–Ω—ñ', ' ', '–ø—Ä–∏—Å–ª—ñ–≤', \"'\", '—è', ' ', '—Ç–∞', ' ', '–ø—Ä–∏–∫–∞–∑–∫–∏', 'üòÉ']\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"–£–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –Ω–∞—Ä–æ–¥-\n",
    "–Ω—ñ –ø—Ä–∏—Å–ª—ñ–≤'—è —Ç–∞ –ø—Ä–∏–∫–∞–∑–∫–∏üòÉ\"\"\"\n",
    "tokens = text_to_tokens(input_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd33202-620b-4148-93ad-9d0f0a20d6cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DAG\n",
    "\n",
    "`EntitiesDAG` - data structure designed to store info about text.\n",
    "\n",
    "`EntitiesDAG` consists of `BaseEntity` objects. Each entity contains info about next and previous entities, as well as info about entities which are deduced from itself (at least partially).<br>\n",
    "Wnen initialized from tokens `EntitiesDAG` is created as chain of `ConnectingEntity -> TextEntity -> ... -> ConnectingEntity` entities, where all `TextEntity` are initialized from tokens and surrounded by `ConnectingEntity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b8b5b9-bb8f-4f6f-b7c0-5f5797a8e43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntitiesDAG<pandas  designed to make working\n",
       "with \"relational\" or \"label...sy and intuitive.>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = '''pandas  designed to make working\n",
    "with \"relational\" or \"labeled\" data both easy and intuitive.'''\n",
    "tokens = text_to_tokens(input_text)\n",
    "dag = EntitiesDAG(tokens)\n",
    "dag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c76dbc-32db-40f0-b1c9-7e55e809ab1d",
   "metadata": {},
   "source": [
    "Representing such DAG in a pretty way requires significant additional coding and was't implemented properly. Instead, `pprint` method was implemented which prints all tokens in a way, that all consequent tokens are further to the right than tokens which precedes them. `pprint` also support `max_width` argument to print DAG on multiple lines if it doesn't fit one\n",
    "\n",
    "`pprint` use `__str__` method to print entities.<br>\n",
    "`TextEntity` objects are printed as their Python representation (without quotes).<br>\n",
    "`ConnectingEntity` represented as \"‚Ä¢\" symbol (BULLET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20636525-907d-4697-9921-50a4139df753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ä¢pandas‚Ä¢ ‚Ä¢ ‚Ä¢designed‚Ä¢ ‚Ä¢to‚Ä¢ ‚Ä¢make‚Ä¢ ‚Ä¢working‚Ä¢\\n‚Ä¢with‚Ä¢ ‚Ä¢\"‚Ä¢relational‚Ä¢\"‚Ä¢ ‚Ä¢\n",
      "----------------------------------------------------------------------\n",
      "or‚Ä¢ ‚Ä¢\"‚Ä¢labeled‚Ä¢\"‚Ä¢ ‚Ä¢data‚Ä¢ ‚Ä¢both‚Ä¢ ‚Ä¢easy‚Ä¢ ‚Ä¢and‚Ä¢ ‚Ä¢intuitive‚Ä¢.‚Ä¢\n"
     ]
    }
   ],
   "source": [
    "dag.pprint(max_width=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98037ccb-5af9-43e1-bff2-104c04c3a239",
   "metadata": {},
   "source": [
    "# Analysers: Punctuation, Spacing, Numbers\n",
    "\n",
    "Further work with a DAG implemented with analysers, which adds new entities to existing DAG.<br>\n",
    "For example, `spacing_analyser`, `punctuation_analyser`, `integer_analyser` match predefined sequences of `TextEntity` and add new entities to the DAG if matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb0eed3-efbd-4f9c-bf51-f999589ae1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ä¢How‚Ä¢ ‚Ä¢to‚Ä¢ ‚Ä¢convert‚Ä¢ ‚Ä¢variable‚Ä¢ ‚Ä¢into‚Ä¢ ‚Ä¢numpy‚Ä¢.‚Ä¢int‚Ä¢64‚Ä¢?‚Ä¢\\n‚Ä¢\\t‚Ä¢-‚Ä¢ ‚Ä¢Answer‚Ä¢ ‚Ä¢is‚Ä¢ \n",
      "--------------------------------------------------------------------------------\n",
      "‚Ä¢simple‚Ä¢.‚Ä¢.‚Ä¢.‚Ä¢\n"
     ]
    }
   ],
   "source": [
    "input_text = '''How to convert variable into numpy.int64?\n",
    "\\t- Answer is simple...'''\n",
    "tokens = text_to_tokens(input_text)\n",
    "dag = EntitiesDAG(tokens)\n",
    "dag.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d53f1e3-7951-4966-914a-d72ffd9970c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ä¢How‚Ä¢ ‚Ä¢to‚Ä¢ ‚Ä¢convert‚Ä¢ ‚Ä¢variable‚Ä¢ ‚Ä¢into‚Ä¢ ‚Ä¢numpy‚Ä¢.‚Ä¢int‚Ä¢64‚Ä¢?‚Ä¢\\n‚Ä¢\\t‚Ä¢-‚Ä¢ ‚Ä¢Answer‚Ä¢ ‚Ä¢is‚Ä¢ \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                 ‚ê£        ‚ê£    ‚ê£\n",
      "                                                         ‚ê£  ‚ê£  Punct<->\n",
      "                                                       Punct<?>\n",
      "                                                    N<64>\n",
      "     ‚ê£    ‚ê£         ‚ê£          ‚ê£      ‚ê£       Punct<.>\n",
      "--------------------------------------------------------------------------------\n",
      "‚Ä¢simple‚Ä¢.‚Ä¢.‚Ä¢.‚Ä¢\n",
      "            Punct<.>\n",
      "          Punct<.>\n",
      "        Punct<.>\n",
      "        Punct<...>\n"
     ]
    }
   ],
   "source": [
    "spacing_analyser.analyse(dag)\n",
    "punctuation_analyser.analyse(dag)\n",
    "integer_analyser.analyse(dag)\n",
    "\n",
    "dag.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f59925-d968-4d51-9e71-0c9eacab0c34",
   "metadata": {},
   "source": [
    "P.S. Due to current limitations of `pprint` method obtained representation of all entities of a DAG contains a lot of empty space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
